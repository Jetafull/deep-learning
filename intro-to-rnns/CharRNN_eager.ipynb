{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('anna.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "vocab = sorted(set(text))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)\n",
    "\n",
    "def get_batches(arr, batch_size, n_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    # Get the number of characters per batch and number of batches we can make\n",
    "    chars_per_batch = batch_size * n_steps\n",
    "    n_batches = len(arr)//chars_per_batch\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * chars_per_batch]\n",
    "    \n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y_temp = arr[:, n+1:n+n_steps+1]\n",
    "        \n",
    "        # For the very last batch, y will be one character short at the end of \n",
    "        # the sequences which breaks things. To get around this, I'll make an \n",
    "        # array of the appropriate size first, of all zeros, then add the targets.\n",
    "        # This will introduce a small artifact in the last batch, but it won't matter.\n",
    "        y = np.zeros(x.shape, dtype=x.dtype)\n",
    "        y[:,:y_temp.shape[1]] = y_temp\n",
    "        \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100        # Sequences per batch\n",
    "num_steps = 100         # Number of sequence steps per batch\n",
    "lstm_size = 512         # Size of hidden layers in LSTMs\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "learning_rate = 0.001   # Learning rate\n",
    "keep_prob = 0.5         # Dropout keep probability\n",
    "\n",
    "epochs = 20\n",
    "# Print losses every N interations\n",
    "print_every_n = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 100), (100, 100))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cell(lstm_size, keep_prob):\n",
    "    # Use a basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "\n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    return drop\n",
    "cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)] )\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot = tf.one_hot(x, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(100), Dimension(83)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(100), Dimension(512)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor: id=7161, shape=(100, 512), dtype=float32, numpy=\n",
       "array([[-0.01368002,  0.00426607, -0.00336585, ...,  0.01164236,\n",
       "        -0.00806775,  0.01354871],\n",
       "       [ 0.00271294,  0.02735158, -0.02770866, ..., -0.01740349,\n",
       "        -0.03233358,  0.01301287],\n",
       "       [ 0.02291019,  0.02089741,  0.00133606, ...,  0.02235182,\n",
       "        -0.01734058, -0.01720683],\n",
       "       ...,\n",
       "       [-0.01667213, -0.00839673,  0.02491918, ..., -0.02335074,\n",
       "         0.00675694,  0.02741068],\n",
       "       [ 0.02162038,  0.04120306,  0.00279209, ..., -0.00942402,\n",
       "         0.01755924,  0.02493419],\n",
       "       [ 0.00657174,  0.01228187, -0.01015169, ..., -0.01198205,\n",
       "         0.01444579,  0.01733122]], dtype=float32)>, h=<tf.Tensor: id=7164, shape=(100, 512), dtype=float32, numpy=\n",
       "array([[-0.00675584,  0.00209218, -0.00169965, ...,  0.00569445,\n",
       "        -0.00413005,  0.00680441],\n",
       "       [ 0.00137915,  0.01376002, -0.01358947, ..., -0.00874368,\n",
       "        -0.01606269,  0.00663864],\n",
       "       [ 0.01153642,  0.0106244 ,  0.00066051, ...,  0.01138464,\n",
       "        -0.00866602, -0.00866729],\n",
       "       ...,\n",
       "       [-0.00829318, -0.00422779,  0.01219966, ..., -0.01151677,\n",
       "         0.00336496,  0.0140725 ],\n",
       "       [ 0.01050691,  0.02102475,  0.00136787, ..., -0.00480263,\n",
       "         0.00879443,  0.01227403],\n",
       "       [ 0.00322671,  0.0060451 , -0.00514575, ..., -0.00585945,\n",
       "         0.00725982,  0.00855473]], dtype=float32)>),\n",
       " LSTMStateTuple(c=<tf.Tensor: id=7190, shape=(100, 512), dtype=float32, numpy=\n",
       "array([[ 0.01715678,  0.00820013, -0.00444758, ..., -0.00840618,\n",
       "         0.02433274, -0.00986064],\n",
       "       [ 0.00677667,  0.01436508, -0.0078785 , ..., -0.01580425,\n",
       "        -0.00067151, -0.00410759],\n",
       "       [ 0.02000284,  0.01420787,  0.00350678, ..., -0.01074903,\n",
       "        -0.0066579 ,  0.01293782],\n",
       "       ...,\n",
       "       [ 0.00029073,  0.03156708, -0.00956956, ..., -0.00650148,\n",
       "         0.02045592,  0.0127988 ],\n",
       "       [ 0.01206655,  0.03459086, -0.006027  , ...,  0.00259475,\n",
       "         0.01446174,  0.01186903],\n",
       "       [ 0.01891108,  0.0327899 ,  0.00954521, ...,  0.00529928,\n",
       "         0.01111372,  0.02500727]], dtype=float32)>, h=<tf.Tensor: id=7193, shape=(100, 512), dtype=float32, numpy=\n",
       "array([[ 0.00856479,  0.00409064, -0.00222571, ..., -0.00418238,\n",
       "         0.01226222, -0.00492833],\n",
       "       [ 0.0033592 ,  0.00724804, -0.00394821, ..., -0.00777711,\n",
       "        -0.00033754, -0.00205602],\n",
       "       [ 0.01005106,  0.00710078,  0.00175973, ..., -0.00535768,\n",
       "        -0.00336582,  0.0065192 ],\n",
       "       ...,\n",
       "       [ 0.00014427,  0.0158311 , -0.00482398, ..., -0.00322352,\n",
       "         0.01031164,  0.00635002],\n",
       "       [ 0.0060325 ,  0.0173937 , -0.00300552, ...,  0.00129047,\n",
       "         0.00723172,  0.00594287],\n",
       "       [ 0.00943084,  0.01657038,  0.00475076, ...,  0.00263346,\n",
       "         0.00556678,  0.01264792]], dtype=float32)>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
